{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetoVisao.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoralcantara75/artworks_classifier/blob/master/ProjetoVisao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi8bRAKZ2xDn",
        "colab_type": "text"
      },
      "source": [
        "# BEST ARTWORKS OF ALL TIME \n",
        "## PROJETO DISCIPLINA - VISÃO COMPUTACIONAL "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZEUg9l3Cjt",
        "colab_type": "text"
      },
      "source": [
        "##IMPORTAÇÕES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D7bsmHZNTl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "from torchvision import datasets, models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHm1fzTnIhZ3",
        "colab_type": "code",
        "outputId": "12f47d6c-d348-434e-c5f9-9602ce1e41e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/victoralcantara75/best-artworks-of-all-time.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'best-artworks-of-all-time' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRgQeZkyG5Ht",
        "colab_type": "code",
        "outputId": "2b32dde4-d7b6-4835-efbb-d6dc3713a22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "epocas = 40\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uesch_zFyaw5",
        "colab": {}
      },
      "source": [
        "def diretorio_dados(k):\n",
        "  \n",
        "    diretorio = \"best-artworks-of-all-time/5-fold/round_\"+str(k)+\"/\"\n",
        "    \n",
        "    diretorio_teste = diretorio + \"test/\"\n",
        "    diretorio_validacao = diretorio+ \"val/\"\n",
        "    diretorio_train = diretorio + \"train/\"\n",
        "    \n",
        "    return  diretorio_train, diretorio_validacao, diretorio_teste"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HZylBPHCAJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformacoes():\n",
        "  \n",
        "    transformation = transforms.Compose([ \n",
        "                       transforms.Resize(224),\n",
        "                       transforms.RandomCrop(224),\n",
        "                       transforms.RandomHorizontalFlip(),\n",
        "                       transforms.RandomVerticalFlip(),\n",
        "                       transforms.RandomRotation(15),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "\n",
        "    \n",
        "    transformation_test = transforms.Compose([ \n",
        "                          transforms.Resize(224),\n",
        "                          transforms.RandomResizedCrop(224),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "    \n",
        "    return transformation, transformation_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnBKU2czBQLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def carregar_dados():\n",
        "  \n",
        "    transf, transf_t = transformacoes()\n",
        "    \n",
        "    img_treino = datasets.ImageFolder(dir_treino, transf)\n",
        "    img_validacao = datasets.ImageFolder(dir_validacao, transf_t)\n",
        "    img_teste = datasets.ImageFolder(dir_teste, transf_t)\n",
        "    \n",
        "    print('Numero de imagens de treino: ', len(img_treino))\n",
        "    print('Numero de imagens de validacao: ', len(img_validacao))\n",
        "    print('Numero de imagens de teste: ', len(img_teste))\n",
        "    \n",
        "    num_workers=4\n",
        "\n",
        "    treino = torch.utils.data.DataLoader(img_treino, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "    validacao = torch.utils.data.DataLoader(img_validacao, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "    teste = torch.utils.data.DataLoader(img_teste, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
        "    \n",
        "    return treino, validacao, teste"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjcwXGJwUwQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(train_loss, train_accu, test_loss, test_accu, k):\n",
        "    \n",
        "    #Index, used to show epoch values\n",
        "    listaDeIndex = []\n",
        "    listaDeIndex2 = []\n",
        "\n",
        "    for i in range(1, len(train_loss)+1):\n",
        "        listaDeIndex.append(i)\n",
        "\n",
        "    for i in range(1, len(test_loss)+1):\n",
        "        listaDeIndex2.append(i)\n",
        "\n",
        "    accText = ' Gráfico de acurácia em '+str(epocas)+ ' épocas'\n",
        "    lossText = ' Gráfico de perda(loss) em '+str(epocas)+' épocas'\n",
        "\n",
        "    plt.title(accText)\n",
        "    plt.plot(listaDeIndex, train_accu,c='magenta',ls='-',label='Acurácia de treino',fillstyle='none')\n",
        "    plt.plot(listaDeIndex2, test_accu ,c='green'  ,ls='-',label='Acurácia de validacao' ,fillstyle='none')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Acurácia')\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    grafico_de_acuracia = str(\"accround_\"+str(k)+\".png\")\n",
        "    pylab.savefig(grafico_de_acuracia) #Saving\n",
        "    plt.close() #Para não mostrar essa imagem, pq ela ainda fica salva no plt\n",
        "\n",
        "\n",
        "    plt.title(lossText)\n",
        "    plt.plot(listaDeIndex, train_loss,c='magenta',ls='-',label='Erro durante treino',fillstyle='none')\n",
        "    plt.plot(listaDeIndex2, test_loss ,c='green'  ,ls='-',label='Erro durante validacao' ,fillstyle='none')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Erro')\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "    grafico_de_perda = str(\"lossround_\"+str(k)+\".png\")\n",
        "    pylab.savefig(grafico_de_perda) #Saving\n",
        "    plt.close() #Para não mostrar essa imagem, pq ela ainda fica salva no plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhBqqJy6M7lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def treinamento(cnn, criterion, optimizer, epocas):\n",
        "\n",
        "  for epoch in range (1, epocas+1):  # loop over the dataset multiple times\n",
        "      \n",
        "      #---------------------- TREINO --------------------\n",
        "    \n",
        "      print('\\nEpoca {}/{}'.format(epoch, epocas))\n",
        "    \n",
        "      cnn.train()\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "      \n",
        "      for i, data in enumerate(treino, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = cnn(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "          \n",
        "          epoch_loss = running_loss / len(treino.dataset)\n",
        "          epoch_acc = running_corrects.double() / len(treino.dataset)\n",
        "          \n",
        "      print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "      #-------------------------- VALIDACAO --------------------\n",
        "      \n",
        "      cnn.eval()\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "      \n",
        "      with torch.no_grad():\n",
        "         for i, data in enumerate(treino, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = cnn(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "          \n",
        "          epoch_loss = running_loss / len(treino.dataset)\n",
        "          epoch_acc = running_corrects.double() / len(treino.dataset)\n",
        "          \n",
        "      print('Valid - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))     \n",
        "              \n",
        "  print('Finished Training')\n",
        "  \n",
        "  #------------------------- TESTE --------------------\n",
        "  cnn.eval()\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "\n",
        "  classes = [\"Albrecht_Dürer\", \"Alfred_Sisley\", \"Amedeo_Modigliani\", \"Andrei_Rublev\", \"Andy_Warhol\", \"Camille_Pissarro\", \"Caravaggio\", \"Claude_Monet\", \"Diego_Rivera\", \"Diego_Velazquez\", \"Edgar_Degas\", \"Edouard_Manet\", \"Edvard_Munch\", \"El_Greco\", \"Eugene_Delacroix\", \"Francisco_Goya\", \"Frida_Kahlo\", \"Georges_Seurat\", \"Giotto_di_Bondone\", \"Gustav_Klimt\", \"Gustave_Courbet\", \"Henri_de_Toulouse-Lautrec\", \"Henri_Matisse\", \"Henri_Rousseau\", \"Hieronymus_Bosch\", \"Jackson_Pollock\", \"Jan_van_Eyck\", \"Joan_Miro\", \"Kazimir_Malevich\", \"Leonardo_da_Vinci\", \"Marc_Chagall\", \"Michelangelo\", \"Mikhail_Vrubel\", \"Pablo_Picasso\", \"Paul_Cezanne\", \"Paul_Gauguin\", \"Paul_Klee\", \"Peter_Paul_Rubens\", \"Pierre-Auguste_Renoir\", \"Piet_Mondrian\", \"Pieter_Bruegel\", \"Raphael\", \"Rembrandt\", \"Rene_Magritte\", \"Salvador_Dali\", \"Sandro_Botticelli\",\"Titian\", \"Vasiliy_Kandinskiy\", \"Vincent_van_Gogh\", \"William_Turner\"]\n",
        "  class_correct = list(0. for i in range(50))\n",
        "  class_total = list(0. for i in range(50))\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for data in teste:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = cnn(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          corrects += (predicted == labels).sum().item()\n",
        "\n",
        "          running_corrects += (predicted == labels).sum().item()\n",
        "          correct_tensor = predicted.eq(labels.data.view_as(predicted))    #comparando respostas corretas\n",
        "          correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "          for i in range(len(correct_tensor)):\n",
        "            label = labels.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "      for i in range(50):\n",
        "        if class_total[i] > 0:\n",
        "            print('Acurácia do teste classe '+classes[i]+': %2d%% (%2d/%2d)' % (100 * class_correct[i] / class_total[i],np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "        else:\n",
        "            print('Acurácia do teste classe %5s: N/A (sem exemplos de treinamento)')\n",
        "\n",
        "      acc = (100 * corrects / total)\n",
        "\n",
        "  plot_graph(train_loss_list, train_accu_list, valid_loss_list, valid_accu_list, k)\n",
        "  print('Acuracia total do round: ', acc)\n",
        "\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0QiS_G3DuMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#IMPORTANDO REDE \n",
        "cnn = models.resnet50(pretrained=True)\n",
        "\n",
        "#MUDANDO NUMERO DE CLASSES DE SAIDA\n",
        "cnn.fc.out_features = 50\n",
        "\n",
        "# Especificando a loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Definindo o Otimizador\n",
        "otimizador = optim.SGD(cnn.parameters(), lr=learning_rate)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  cnn.cuda()\n",
        "  print(' ')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Z6q_LjW8PP",
        "colab_type": "code",
        "outputId": "62ece316-11f5-4483-bc63-263beee25e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "acuracias = []\n",
        "\n",
        "for k in range (1, 6):\n",
        "\n",
        "  #CARREGANDO DATASET \n",
        "  dir_treino, dir_validacao, dir_teste = diretorio_dados(k)\n",
        "  treino, validacao, teste = carregar_dados()\n",
        "\n",
        "  acc = treinamento(cnn, criterion, otimizador, epocas)\n",
        "  acuracias.append(acc)\n",
        "\n",
        "resultado = sum(acuracias) / 5\n",
        "\n",
        "print('\\nRESULTADO FINAL : %2d%% ' % (resultado))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de imagens de treino:  4709\n",
            "Numero de imagens de validacao:  1203\n",
            "Numero de imagens de teste:  2534\n",
            "\n",
            "Epoca 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-af324049c8c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidacao\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarregar_dados\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreinamento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motimizador\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepocas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0macuracias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1a16e139df94>\u001b[0m in \u001b[0;36mtreinamento\u001b[0;34m(cnn, criterion, optimizer, epocas)\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}